#!/usr/bin/env python3
"""
Update Latest MOT Data Script - Simple Version

‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å MOT API ‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏Ç‡πâ‡∏≤ PostgreSQL features table
‡πÉ‡∏ä‡πâ query ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£

Current situation:
- DB latest: 2025-09-03 (September)  
- Today: 2025-10-01 (October)
- Query: September + October 2025
"""

import psycopg2
import pandas as pd
import requests
from datetime import datetime, date
import sys
from typing import Optional, Dict, List, Any

# Database configuration
DB_CONFIG = {
    "host": "localhost",
    "port": 5432,
    "dbname": "airflow",
    "user": "airflow",
    "password": "airflow"
}

def get_latest_date_from_db() -> Optional[date]:
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()
        
        cur.execute("SELECT MAX(feature_date) FROM features;")
        result = cur.fetchone()
        latest_date = result[0] if result[0] else None
        
        cur.close()
        conn.close()
        
        return latest_date
    except Exception as e:
        print(f"‚ùå Error getting latest date: {e}")
        return None

def fetch_mot_data_for_months(year: int, months: List[int]) -> Optional[List[Dict[str, Any]]]:
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• MOT API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏"""
    url = "https://datagov.mot.go.th/api/action/datastore_search"
    all_records = []
    
    for month in months:
        query_month = f"{year}-{month:02d}"
        print(f"üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏î‡∏∑‡∏≠‡∏ô: {query_month}")
        
        params = {
            "resource_id": "a139ab23-602f-4c0d-8789-4d230bcdf33d",
            "q": f"{query_month}",
            "limit": 10000
        }
        
        try:
            response = requests.get(url, params=params)
            response.raise_for_status()
            data = response.json()
            
            if 'result' not in data or 'records' not in data['result']:
                print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô {query_month}")
                continue
            
            records = data['result']['records']
            print(f"üìä ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô {query_month}: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ {len(records)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            all_records.extend(records)
        
        except Exception as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÄ‡∏î‡∏∑‡∏≠‡∏ô {query_month}: {e}")
            continue
    
    return all_records if all_records else None

def filter_new_records(records: List[Dict[str, Any]], since_date: date) -> List[Dict[str, Any]]:
    """‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà"""
    new_records = []
    for record in records:
        if '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà' in record and record['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà']:
            try:
                record_date = pd.to_datetime(record['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà']).date()
                if record_date > since_date:
                    new_records.append(record)
            except:
                continue
    
    print(f"üÜï ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà: {len(new_records)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    return new_records

def process_mot_data(records: List[Dict[str, Any]]) -> Optional[pd.DataFrame]:
    """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• MOT ‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    if not records:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
        return None
    
    print("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    
    df = pd.DataFrame(records)
    # df.to_csv('checkpoint.csv', index=False)
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
    df['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà'] = pd.to_datetime(df['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà'], errors='coerce')
    df = df.dropna(subset=['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà'])
    
    if df.empty:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
        return None
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡∏ú‡∏π‡πâ‡πÇ‡∏î‡∏¢‡∏™‡∏≤‡∏£
    df['‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì'] = pd.to_numeric(df['‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì'], errors='coerce').fillna(0)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á pivot table
    pivot_df = df.pivot_table(
        index='‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà',
        columns='‡∏¢‡∏≤‡∏ô‡∏û‡∏≤‡∏´‡∏ô‡∏∞/‡∏ó‡πà‡∏≤',
        values='‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì',
        aggfunc='sum',
        fill_value=0
    ).reset_index()
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å pivot
    pivot_columns = [col for col in pivot_df.columns if col != '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà']
    print(f"üìä ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏à‡∏≤‡∏Å pivot: {pivot_columns}")
    
    # Merge ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏°‡πà‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠)
    
    # ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏¢
    line_groups = {
        'ARL': ['arl', 'ARL', '‡∏™‡∏∏‡∏ß‡∏£‡∏£‡∏ì‡∏†‡∏π‡∏°‡∏¥'],
        'BTS': ['bts', 'BTS', '‡∏•‡∏π‡∏Å‡∏ü‡∏π‡∏Å'],
        '‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô': ['‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô', '‡∏ô‡∏≥‡πÄ‡∏á‡∏¥‡∏ô', '‡∏ô‡πâ‡∏≤‡πÄ‡∏á‡∏¥‡∏ô', '‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô'],
        '‡∏°‡πà‡∏ß‡∏á': ['‡∏°‡πà‡∏ß‡∏á', '‡∏°‡∏ß‡∏á', '‡∏™‡∏µ‡∏°‡πà‡∏ß‡∏á'],
        '‡∏ä‡∏°‡∏û‡∏π': ['‡∏ä‡∏°‡∏û‡∏π', '‡∏ä‡∏°‡∏û‡∏π‡∏π', '‡∏ä‡∏°‡∏û‡∏∏', '‡∏™‡∏µ‡∏ä‡∏°‡∏û‡∏π'],
        '‡πÅ‡∏î‡∏á': ['‡πÅ‡∏î‡∏á', '‡πÅ‡∏î‡∏á', '‡∏™‡∏µ‡πÅ‡∏î‡∏á', '‡∏ä‡∏≤‡∏ô‡πÄ‡∏°‡∏∑‡∏≠‡∏á'],
        '‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á': ['‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á', '‡πÄ‡∏´‡∏•‡∏∑‡∏á', '‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á']
    }
    
    for line_key, keywords in line_groups.items():
        # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏µ‡πâ
        matching_cols = []
        for col in pivot_columns:
            if any(keyword in col for keyword in keywords):
                matching_cols.append(col)
        
        if len(matching_cols) > 1:
            print(f"üîÑ ‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå {line_key} ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß: {matching_cols}")
            # ‡∏£‡∏ß‡∏°‡∏Ñ‡πà‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÅ‡∏£‡∏Å
            main_col = matching_cols[0]
            for other_col in matching_cols[1:]:
                pivot_df[main_col] = pivot_df[main_col] + pivot_df[other_col]
                pivot_df = pivot_df.drop(columns=[other_col])
            print(f"‚úÖ ‡∏£‡∏ß‡∏° {line_key} ‡πÄ‡∏õ‡πá‡∏ô: {main_col}")
        elif len(matching_cols) == 1:
            print(f"‚úÖ {line_key}: {matching_cols[0]}")
    
    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å merge
    pivot_columns = [col for col in pivot_df.columns if col != '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà']
    print(f"üìä ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏´‡∏•‡∏±‡∏á merge: {pivot_columns}")

    # mapping ‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏¢‡∏≤‡∏ô‡∏û‡∏≤‡∏´‡∏ô‡∏∞‡πÑ‡∏õ column ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
    vehicle_mapping = {
        '‡∏£‡∏ñ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤ ARL': 'arl',
        '‡∏£‡∏ñ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤ BTS': 'bts', 
        '‡∏£‡∏ñ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤‡∏™‡∏≤‡∏¢‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô': 'mrt_blue',
        '‡∏£‡∏ñ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤‡∏™‡∏≤‡∏¢‡∏™‡∏µ‡∏°‡πà‡∏ß‡∏á': 'mrt_purple',
        '‡∏£‡∏ñ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤‡∏™‡∏≤‡∏¢‡∏™‡∏µ‡∏ä‡∏°‡∏û‡∏π': 'mrt_pink',
        '‡∏£‡∏ñ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤‡∏™‡∏≤‡∏¢‡∏™‡∏µ‡πÅ‡∏î‡∏á': 'srt_red',
        '‡∏£‡∏ñ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤‡∏™‡∏≤‡∏¢‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á': 'mrt_yellow'
    }
    
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    result_data = []
    pivot_columns = [col for col in pivot_df.columns if col != '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà']
    
    for _, row in pivot_df.iterrows():
        record_date = row['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà'].date()
        dow = record_date.weekday()  # 0=Monday, 6=Sunday
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á record
        record = {
            'feature_date': record_date,
            'day_type': -1,  # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô -1 ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏£‡πâ‡∏≠‡∏á‡∏Ç‡∏≠
            'dow': dow,
            'rain_average': None,  # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô null ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏£‡πâ‡∏≠‡∏á‡∏Ç‡∏≠
            'arl': 0.0,
            'bts': 0.0,
            'mrt_blue': 0.0,
            'mrt_purple': 0.0,
            'srt_red': 0.0,
            'mrt_yellow': 0.0,
            'mrt_pink': 0.0
        }
        
        # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏≤‡∏ô‡∏û‡∏≤‡∏´‡∏ô‡∏∞‡∏à‡∏≤‡∏Å pivot table
        for pivot_col in pivot_columns:
            for vehicle_name, target_col in vehicle_mapping.items():
                if vehicle_name in pivot_col:
                    record[target_col] = float(row.get(pivot_col, 0))
                    break
        
        result_data.append(record)
    
    result_df = pd.DataFrame(result_data)
    
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡πà‡∏≠‡∏ô return
    result_df = result_df.sort_values('feature_date').reset_index(drop=True)
    
    print(f"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô: {len(result_df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    print(f"üìÖ ‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {result_df['feature_date'].min()} ‡∏ñ‡∏∂‡∏á {result_df['feature_date'].max()}")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• (3 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏£‡∏Å)
    print("\nüìä ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•:")
    for idx, row in result_df.head(3).iterrows():
        transport_info = []
        if row['arl'] > 0: transport_info.append(f"ARL={row['arl']:.0f}")
        if row['bts'] > 0: transport_info.append(f"BTS={row['bts']:.0f}")
        if row['mrt_blue'] > 0: transport_info.append(f"Blue={row['mrt_blue']:.0f}")
        if row['mrt_purple'] > 0: transport_info.append(f"Purple={row['mrt_purple']:.0f}")
        if row['mrt_pink'] > 0: transport_info.append(f"Pink={row['mrt_pink']:.0f}")
        if row['srt_red'] > 0: transport_info.append(f"Red={row['srt_red']:.0f}")
        if row['mrt_yellow'] > 0: transport_info.append(f"Yellow={row['mrt_yellow']:.0f}")
        
        transport_str = ", ".join(transport_info) if transport_info else "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
        print(f"  {row['feature_date']}: {transport_str}")
    
    return result_df

def insert_new_data(df: pd.DataFrame) -> bool:
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"""
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å (‡πÄ‡∏Å‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô)
        df = df.sort_values('feature_date').reset_index(drop=True)
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö columns ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á
        cols = [
            "feature_date", "day_type", "dow", "rain_average",
            "arl", "bts", "mrt_blue", "mrt_purple",
            "srt_red", "mrt_yellow", "mrt_pink"
        ]
        df = df[cols]
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
        print(f"üíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà)...")
        print(f"üìÖ ‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {df['feature_date'].iloc[0]} ‡∏ñ‡∏∂‡∏á {df['feature_date'].iloc[-1]}")
        
        if len(df) <= 7:
            for idx, row in df.iterrows():
                transport_info = []
                if row['arl'] > 0: transport_info.append(f"ARL={row['arl']:.0f}")
                if row['bts'] > 0: transport_info.append(f"BTS={row['bts']:.0f}")
                transport_str = ", ".join(transport_info) if transport_info else "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
                print(f"  {row['feature_date']}: {transport_str}")
        else:
            print(f"  ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏£‡∏Å: {df.iloc[0]['feature_date']}")
            print(f"  ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢: {df.iloc[-1]['feature_date']}")
        
        # ‡πÉ‡∏ä‡πâ bulk UPSERT ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤
        upsert_sql = """
        INSERT INTO features (feature_date, day_type, dow, rain_average, arl, bts, mrt_blue, mrt_purple, srt_red, mrt_yellow, mrt_pink)
        VALUES %s
        ON CONFLICT (feature_date) 
        DO UPDATE SET 
            day_type = EXCLUDED.day_type,
            dow = EXCLUDED.dow,
            rain_average = EXCLUDED.rain_average,
            arl = EXCLUDED.arl,
            bts = EXCLUDED.bts,
            mrt_blue = EXCLUDED.mrt_blue,
            mrt_purple = EXCLUDED.mrt_purple,
            srt_red = EXCLUDED.srt_red,
            mrt_yellow = EXCLUDED.mrt_yellow,
            mrt_pink = EXCLUDED.mrt_pink
        """
        
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö bulk insert
        from psycopg2.extras import execute_values
        values = [tuple(row) for row in df.values]
        
        # Execute bulk insert
        execute_values(cur, upsert_sql, values, template=None, page_size=100)
        
        conn.commit()
        cur.close()
        conn.close()
        
        print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà)")
        return True
        
    except Exception as e:
        print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {e}")
        return False

def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å"""
    print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• MOT")
    
    # 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    latest_date = get_latest_date_from_db()
    if latest_date is None:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÑ‡∏î‡πâ")
        return False
    
    print(f"üìÖ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {latest_date}")
    
    # 2. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á query ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
    from datetime import datetime
    
    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    latest_year = latest_date.year
    latest_month = latest_date.month
    
    # ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
    today = datetime.now().date()
    current_year = today.year
    current_month = today.month
    
    print(f"üìä ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö: DB({latest_year}-{latest_month:02d}) vs ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô({current_year}-{current_month:02d})")
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á query
    months_to_query = []
    years_to_query = set()
    
    if latest_year == current_year and latest_month == current_month:
        # ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô - query ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        months_to_query = [(current_year, current_month)]
        print(f"‚úÖ ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô: query ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ {current_year}-{current_month:02d}")
    else:
        # ‡∏ï‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô - query ‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        months_to_query = [(latest_year, latest_month), (current_year, current_month)]
        
        # ‡∏•‡∏ö duplicate ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
        months_to_query = list(set(months_to_query))
        months_to_query.sort()  # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö
        
        print(f"ÔøΩ ‡∏ï‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô: query {len(months_to_query)} ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô")
        for year, month in months_to_query:
            print(f"   - {year}-{month:02d}")
    
    # ‡πÅ‡∏¢‡∏Å query ‡∏ï‡∏≤‡∏°‡∏õ‡∏µ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ API ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ
    query_plan = {}
    for year, month in months_to_query:
        if year not in query_plan:
            query_plan[year] = []
        query_plan[year].append(month)
    
    print(f"üóìÔ∏è  ‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {dict(query_plan)}")
    
    # 3. ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å API ‡∏ï‡∏≤‡∏° query plan
    all_records = []
    for year, months in query_plan.items():
        print(f"\nüîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏µ {year}")
        year_records = fetch_mot_data_for_months(year, months)
        if year_records:
            all_records.extend(year_records)
    
    if not all_records:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å API ‡πÑ‡∏î‡πâ")
        return False
    
    print(f"üìà ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(all_records)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    
    # 4. ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà
    new_records = filter_new_records(all_records, latest_date)
    if not new_records:
        print("‚úÖ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï")
        return True
    
    # 5. ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    df = process_mot_data(new_records)
    if df is None or df.empty:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ")
        return False
    
    # 6. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏Ç‡πâ‡∏≤‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    success = insert_new_data(df)
    
    if success:
        print("üéâ ‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        return True
    else:
        print("‚ùå ‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)