version: "3"
services:

  airflow-webserver:
    hostname: airflow
    container_name: airflow
    image: andrejunior/airflow-spark:latest
    restart: always
    networks: [airflow]
    depends_on:
      - postgres
    #   - minio
      - spark-master
      - spark-worker
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - LOAD_EX=n
      - EXECUTOR=Local
      - PYSPARK_PYTHON=python3
      - _PIP_ADDITIONAL_REQUIREMENTS=openmeteo-requests requests-cache retry-requests numpy pandas psycopg2-binary
    volumes:
      - airflow-data:/usr/local/airflow/data
      - ./src/dags:/usr/local/airflow/dags
      - ./src/spark/applications:/usr/local/spark/applications
      - ./src/spark/assets:/usr/local/spark/assets
    ports:
      - "8085:8080"
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3

  postgres:
    hostname: postgres
    container_name: postgres
    image: postgres:14-bullseye
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
      PGDATA: /data/postgres
    volumes:
      - postgres:/data/postgres
    ports:
      - "5432:5432"
    networks: [airflow]
    restart: on-failure
    healthcheck:
      test: ["CMD", "pg_isready"]
      interval: 60s
      timeout: 20s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1g

#   minio:
#     hostname: bucket
#     container_name: bucket
#     image: bitnamilegacy/minio:latest   
#     environment:
#       MINIO_ROOT_USER: airflow
#       MINIO_ROOT_PASSWORD: airflow
#     ports:
#       - "9000:9000"
#       - "9001:9001"
#     volumes:
#       - minio_data:/data
#     networks: [airflow]
#     healthcheck:
#       test: ["CMD", "curl", "-f", "http://bucket:9000/minio/health/live"]
#       interval: 60s
#       timeout: 20s
#       retries: 3
#     deploy:
#       resources:
#         limits:
#           memory: 400m

#   createbuckets:
#     image: minio/mc
#     networks: [airflow]
#     depends_on:
#       minio:
#         condition: service_healthy
#     entrypoint: >
#       /bin/sh -c "
#       /usr/bin/mc config host add myminio http://bucket:9000 airflow airflow;
#       /usr/bin/mc rm -r --force myminio/airflow || true;
#       /usr/bin/mc mb myminio/airflow || true;
#       /usr/bin/mc anonymous set download myminio/airflow || true;
#       exit 0;
#       "

  spark-master:
    image: bitnamilegacy/spark:3.2.1
    user: root
    hostname: spark
    container_name: spark
    networks: [airflow]
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - _PIP_ADDITIONAL_REQUIREMENTS=openmeteo-requests requests-cache retry-requests numpy pandas psycopg2-binary
    volumes:
      - ./src/spark/applications:/usr/local/spark/applications
      - ./src/spark/assets:/usr/local/spark/assets
    ports:
      - "8081:8080"
      - "7077:7077"
    entrypoint: >
      /bin/bash -c "
      pip install openmeteo-requests requests-cache retry-requests numpy pandas psycopg2-binary &&
      /opt/bitnami/scripts/spark/entrypoint.sh /opt/bitnami/scripts/spark/run.sh
      "
    deploy:
      resources:
        limits:
          memory: 1g

  spark-worker:
    image: bitnamilegacy/spark:3.2.1
    user: root
    hostname: spark-worker
    container_name: spark-worker
    networks: [airflow]
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./src/spark/applications:/usr/local/spark/applications
      - ./src/spark/assets:/usr/local/spark/assets
    depends_on:
      - spark-master
    entrypoint: >
      /bin/bash -c "
      pip install openmeteo-requests requests-cache retry-requests numpy pandas psycopg2-binary &&
      /opt/bitnami/scripts/spark/entrypoint.sh /opt/bitnami/scripts/spark/run.sh
      "
    deploy:
      resources:
        limits:
          memory: 2g

  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin4_container
    restart: always
    networks: [airflow]
    ports:
      - "8888:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@admin.com
      PGADMIN_DEFAULT_PASSWORD: admin
    volumes:
      - pgadmin-data:/var/lib/pgadmin

volumes:
  postgres:
  airflow-data:
  pgadmin-data:
#   minio_data:

networks:
  airflow:
    driver: bridge
